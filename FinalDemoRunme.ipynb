{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pickle\n",
    "from scipy.stats import skew\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import UserInputs2WorkingForm\n",
    "from functions import GetTrainingData\n",
    "from functions import GetSplitTrainingData\n",
    "from functions import GetAllModelsForComparison\n",
    "from functions import GetTESTDataFrameNames\n",
    "from functions import getTESTDataFrame\n",
    "from functions import getBarPlot\n",
    "from functions import getGraphs\n",
    "from functions import getPlot\n",
    "from functions import GenerateComparisonResultFiles\n",
    "from functions import FeatureComparison\n",
    "from functions import GetOnlyTwoModelsForComparison\n",
    "from functions import GetFinalEightModelsForComparison\n",
    "from functions import GetFinalModelForComparison\n",
    "from functions import TrainModel\n",
    "from functions import PredictModel\n",
    "from functions import PredictProbModel\n",
    "from functions import GenerateIMSDictionary\n",
    "from functions import GenerateTrainingFile\n",
    "from functions import Magnitude\n",
    "from functions import getValuesFromRawData\n",
    "from functions import getTESTMatrix\n",
    "from functions import GetReducedFeatureArraysFromDataFrame\n",
    "from functions import GetFinalReducedFeatureArraysFromDataFrame\n",
    "from functions import Get10FeaturesFromDataFrame\n",
    "from functions import ReducedFeatureComparison\n",
    "from functions import GenerateFeatureFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "GENERATE TRAINING DATA FILE\n",
    "\"\"\"\n",
    "#GenerateTrainingFile(\"FinalTrainingData.csv\")\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'2003.10.22.12.06.24' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6ea237859dda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'2003.10.22.12.06.24'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtrainingfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"NotNormalized.csv\"\u001b[0m \u001b[0;31m#FinalTrainingData.csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mUserInput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerateIMSDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainingfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'finished'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/10 2020 SPRING/ECEN 404/Programs/ProgramsJan/functions.py\u001b[0m in \u001b[0;36mGenerateIMSDictionary\u001b[0;34m(FileOfInterest, TrainingDataFile, HomeDirectory)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0mSampleFrequency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20000\u001b[0m \u001b[0;31m#Sampling Frequency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0mFileName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFileOfInterest\u001b[0m \u001b[0;31m#Filename in string format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetIMSB1XData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFileName\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Get the bearing 1: X direction from the filename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m     \u001b[0mHomeDirectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHomeDirectory\u001b[0m \u001b[0;31m#Homedirectory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0mdirectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHomeDirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Files HomeDirectory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/10 2020 SPRING/ECEN 404/Programs/ProgramsJan/functions.py\u001b[0m in \u001b[0;36mgetIMSB1XData\u001b[0;34m(FileOfInterest)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \"\"\"\n\u001b[1;32m    304\u001b[0m     \u001b[0;31m#Get Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFileOfInterest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'b1x'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'b1y'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'b2x'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'b2y'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'b3x'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'b3y'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'b4x'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'b4y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'2003.10.22.12.06.24' does not exist"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "'SIMULATE' RECEIVING GUI INPUT\n",
    "\"\"\"\n",
    "\n",
    "filename = '2003.10.22.12.06.24'\n",
    "trainingfilename = \"NotNormalized.csv\" #FinalTrainingData.csv\n",
    "UserInput = GenerateIMSDictionary(filename,trainingfilename,os.getcwd())\n",
    "\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GET TRAINING DATA\n",
    "\"\"\"\n",
    "\n",
    "#Split training datasets for validation\n",
    "#Used in scoring\n",
    "X_train, X_test, Y_train, Y_test = GetSplitTrainingData(UserInput)\n",
    "\n",
    "#For trainging over entire file\n",
    "#Used in final classifier\n",
    "#Not used in scoring\n",
    "Xall_train, Yall_train, dataset = GetTrainingData(UserInput)\n",
    "\n",
    "\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MODEL SELECTION\n",
    "\"\"\"\n",
    "\n",
    "#Quick Demonstration\n",
    "#Get models\n",
    "models = GetOnlyTwoModelsForComparison()\n",
    "#Get Result arrays\n",
    "results,string,string1,time,fig = FeatureComparison(models,X_train, X_test, Y_train, Y_test,UserInput)\n",
    "#Save Result arrays to Files\n",
    "GenerateComparisonResultFiles(results,string,string1,time,fig,str1 = 'zGraphs.pdf',\\\n",
    "                                  str2 = 'zTime.txt',str3 = \"zNoGraphs.txt\",str4 = 'zScore.txt')\n",
    "\n",
    "#Selecting Type of Classifier\n",
    "\"\"\"\n",
    "models = GetAllModelsForComparison()\n",
    "results,string,string1,time,fig = FeatureComparison(models,X_train, X_test, Y_train, Y_test,UserInput)\n",
    "GenerateComparisonResultFiles(results,string,string1,time,fig)\n",
    "\"\"\"\n",
    "\n",
    "#Min Sample Split Comparsion\n",
    "\"\"\"\n",
    "#Generate files as a function of MinSampleSplit\n",
    "for x in range(1,50,2):\n",
    "    print(x)\n",
    "    #Get Models\n",
    "    models = GetFinalEightModelsForComparison(MinSampleSplit=x)\n",
    "    #Get Result arrays\n",
    "    results,string,string1,time,fig = FeatureComparison(models,X_train, X_test, Y_train, Y_test,UserInput)\n",
    "    #Generate Save File Names\n",
    "    Graphname = 'GraphMinSamples' + str(x) + '.pdf'\n",
    "    Timename = 'TimeMinSamples' + str(x) + '.txt'\n",
    "    Scoringname = 'ScoreMinSamples' + str(x) + '.txt'\n",
    "    #Save Result arrays to Files\n",
    "    GenerateComparisonResultFiles(results,string,string1,time,fig,str1 = Graphname,\\\n",
    "                                  str2 = Timename,str3 = \"NoGraphs.txt\",str4 = Scoringname)\n",
    "\"\"\"\n",
    "\n",
    "#Number of Estimators Comparison\n",
    "\"\"\"\n",
    "#Generate files as a function of Nestimators\n",
    "for x in range(10,1010,10):\n",
    "    print(x)\n",
    "    #Get Models\n",
    "    models = GetFinalModelForComparison(MinSampleSplit=10, Nestimators = x)\n",
    "    #Get Result arrays\n",
    "    results,string,string1,time,fig = FeatureComparison(models,X_train, X_test, Y_train, Y_test,UserInput)\n",
    "    #Generate Save File Names\n",
    "    Graphname = 'GraphMinSamples' + str(x) + '.pdf'\n",
    "    Timename = 'TimeMinSamples' + str(x) + '.txt'\n",
    "    Scoringname = 'ScoreMinSamples' + str(x) + '.txt'\n",
    "    #Save Result arrays to Files\n",
    "    GenerateComparisonResultFiles(results,string,string1,time,fig,str1 = Graphname,\\\n",
    "                                  str2 = Timename,str3 = \"NoGraphs.txt\",str4 = Scoringname)\n",
    "\"\"\"\n",
    "\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MODEL VALIDATION\n",
    "\n",
    "Demonstrate Selected Model's results using\n",
    "classification report\n",
    "\n",
    "Test on the split model\n",
    "\"\"\"\n",
    "\n",
    "#Train\n",
    "ClassifierSelectedModel = TrainModel(X_train, Y_train)\n",
    "\n",
    "#Predict\n",
    "Y_pred,Y_pred_string = PredictModel(ClassifierSelectedModel,X_test)\n",
    "\n",
    "#Output Results\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "print('\\nfinished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SAVING FINAL MODEL\n",
    "\n",
    "Train on Final Model using all of the training data\n",
    "\n",
    "Final Model Calling:\n",
    "RandomForestClassifier(min_samples_split = 10 ,n_estimators = 200)\n",
    "\n",
    "Parameters:\n",
    "{   'bootstrap': True, \n",
    "    'class_weight': None, \n",
    "    'criterion': 'gini', \n",
    "    'max_depth': None, \n",
    "    'max_features': 'auto', \n",
    "    'max_leaf_nodes': None, \n",
    "    'min_impurity_decrease': 0.0, \n",
    "    'min_impurity_split': None, \n",
    "    'min_samples_leaf': 1, \n",
    "    'min_samples_split': 10, \n",
    "    'min_weight_fraction_leaf': 0.0, \n",
    "    'n_estimators': 200, \n",
    "    'n_jobs': 1, \n",
    "    'oob_score': False, \n",
    "    'random_state': None, \n",
    "    'verbose': 0, \n",
    "    'warm_start': False}\n",
    "    \n",
    "\"\"\"\n",
    "#Train using All Data\n",
    "FinalClassifier = TrainModel(Xall_train, Yall_train)\n",
    "\n",
    "filename = 'FullModel.sav' #saving name\n",
    "\n",
    "# Save Model Using Pickle\n",
    "#pickle.dump(FinalClassifier, open(filename, 'wb'))\n",
    "\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PREDICTION RESULTS\n",
    "Compared Both Current and Saved Models\n",
    "\n",
    "\"Early\": 0\n",
    "\"Suspect\": 1\n",
    "\"Normal\": 2\n",
    "\"Imminent Failure\": 3\n",
    "\"Inner Race Failure\": 4 \n",
    "\"Rolling Element Failure\": 5\n",
    "\"Stage 2 Failure\": 6\n",
    "\"\"\"\n",
    "\n",
    "#Get test array\n",
    "X_in_question = getTESTMatrix(UserInput)\n",
    "\n",
    "#Currently Trained Model\n",
    "#Predict\n",
    "prediction,prediction_string = PredictModel(FinalClassifier,X_in_question)\n",
    "prediction_proba = PredictProbModel(FinalClassifier,X_in_question)\n",
    "\n",
    "#Output Results\n",
    "print('Current Model:\\n')\n",
    "print(prediction_string)\n",
    "print(prediction_proba)\n",
    "\n",
    "\n",
    "#Saved Model\n",
    "#Load the saved model using Pickle\n",
    "LoadedClassifier = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "#Predict\n",
    "prediction,prediction_string = PredictModel(LoadedClassifier,X_in_question)\n",
    "prediction_proba = PredictProbModel(LoadedClassifier,X_in_question)\n",
    "\n",
    "#Output Results\n",
    "print('\\n')\n",
    "print('Loaded Model:\\n')\n",
    "print(prediction_string)\n",
    "print(prediction_proba)\n",
    "\n",
    "print('\\nfinished')\n",
    "\n",
    "\"\"\"END OF MODEL CHARACTERIZING\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "BEGIN SIMPLIFIED MODEL CHARACTERIZING\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "FEATURE IMPORTANCE\n",
    "\"\"\"\n",
    "\n",
    "#Plot Bar Graph with Most Import Features\n",
    "m = LoadedClassifier.feature_importances_ #Get indices of most important features\n",
    "m1 = GetTESTDataFrameNames(UserInput) #Get the names of the corresponding features\n",
    "Z = [x for _,x in sorted(zip(m,m1))] #correspondingly sort the names according to feature indices (descending)\n",
    "Z1 = sorted(m) #Sort the features importance\n",
    "fig = getBarPlot(Z1[-10:],Z[-10:],\"Relative Importance\",\"FINAL\") #Plot the 10 most important features\n",
    "fig.savefig(\"FeatureExtraction.jpg\", dpi='figure', facecolor='w', edgecolor='w',\n",
    "        orientation='portrait', papertype=None, format=None,\n",
    "        transparent=False, bbox_inches='tight', pad_inches=0.5,\n",
    "        frameon=None, metadata=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "REDUCED MODEL VALIDATION\n",
    "\"\"\"\n",
    "\n",
    "#Load raw data\n",
    "filename = 'NotNormalized.csv'\n",
    "dataset = pd.read_csv(filename,header = 0,index_col = 0)\n",
    "ReducedFeatureTrainingData, StateTrain = GetReducedFeatureArraysFromDataFrame(dataset)\n",
    "\n",
    "\n",
    "#Only show the results of 10 features\n",
    "ReducedFeatureTrainingData, StateTrain = GetFinalReducedFeatureArraysFromDataFrame(dataset)\n",
    "\n",
    "\n",
    "result,header = ReducedFeatureComparison(ReducedFeatureTrainingData,StateTrain)\n",
    "#GenerateFeatureFile('zFeatureSimplicationResults.txt',result,header)\n",
    "\n",
    "print(header[0])\n",
    "print(result[0])\n",
    "print('finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "EXTRACT ACTUAL DATA\n",
    "\"\"\"\n",
    "\n",
    "#Import Raw Data\n",
    "filename = 'AccelerometerActualData.csv'\n",
    "time,amp = getValuesFromRawData(filename)\n",
    "\n",
    "print(time[0:5])\n",
    "print(amp[0:5])\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SIMULATE RECEIVING NEEDED PARAMETERS\n",
    "\"\"\"\n",
    "#Simulate Getting GUI Info\n",
    "n = 50 #will be measured using proximity sensor\n",
    "N = 8 #user inputted\n",
    "Bd = 0.331*254 #user inputted\n",
    "Pd = 2.815*254 #user inputted\n",
    "phi = 15.17 * np.pi / 180 #user inputted\n",
    "SampleFrequency = 680 #known\n",
    "FileName = 'AccelerometerActualData.csv'\n",
    "HomeDirectory = os.getcwd()\n",
    "directory = os.listdir(HomeDirectory)\n",
    "TrainingDataFile = \"NotNormalized.csv\"\n",
    "UserInputWithActualData = UserInputs2WorkingForm(n,N,Bd,Pd,phi,SampleFrequency,FileName,amp,HomeDirectory,directory,TrainingDataFile)\n",
    "\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GET TRAINING DATA\n",
    "\"\"\"\n",
    "#For training over entire file\n",
    "_, State10, dataset_all = GetTrainingData(UserInputWithActualData)\n",
    "Feature10 = Get10FeaturesFromDataFrame(dataset_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SAVING SHORT MODEL\n",
    "This section generates and saves the Machine Learning model\n",
    "\n",
    "This section is not to be run on the actual microcontroller. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "ShortClassifier = TrainModel(Feature10.values[:,0:(Feature10.shape[1]-1)],State10)\n",
    "\n",
    "filename = 'ShortModel.sav'\n",
    "#pickle.dump(ShortClassifier, open(filename, 'wb'))\n",
    "print('finished')\n",
    "\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PREDICTING\n",
    "\n",
    "\"Early\": 0\n",
    "\"Suspect\": 1\n",
    "\"Normal\": 2\n",
    "\"Imminent Failure\": 3\n",
    "\"Inner Race Failure\": 4 \n",
    "\"Rolling Element Failure\": 5\n",
    "\"Stage 2 Failure\": 6\n",
    "\"\"\"\n",
    "\n",
    "#Get Dataframe that would be used with the full model\n",
    "ActualDataFrame = getTESTDataFrame(UserInputWithActualData)\n",
    "\n",
    "#Extract Final 10 Features\n",
    "ActualDataFrame10 = Get10FeaturesFromDataFrame(ActualDataFrame)\n",
    "\n",
    "\n",
    "#Currently Trained Model\n",
    "#Predict\n",
    "prediction,prediction_string = PredictModel(ShortClassifier,ActualDataFrame10.values[:,0:(ActualDataFrame10.shape[1]-1)])\n",
    "prediction_proba = PredictProbModel(ShortClassifier,ActualDataFrame10.values[:,0:(ActualDataFrame10.shape[1]-1)])\n",
    "\n",
    "#Output Results\n",
    "print('Current Model\\n')\n",
    "print(prediction_string)\n",
    "print(prediction_proba)\n",
    "\n",
    "#Saved model\n",
    "#Load the saved model\n",
    "LoadedClassifierShort = pickle.load(open('ShortModel.sav', 'rb'))\n",
    "\n",
    "#Predict\n",
    "prediction,prediction_string = PredictModel(LoadedClassifierShort,ActualDataFrame10.values[:,0:(ActualDataFrame10.shape[1]-1)])\n",
    "prediction_proba = PredictProbModel(LoadedClassifierShort,ActualDataFrame10.values[:,0:(ActualDataFrame10.shape[1]-1)])\n",
    "\n",
    "#Output Results\n",
    "print('\\nLoaded Model\\n')\n",
    "print(prediction_string)\n",
    "print(prediction_proba)\n",
    "\n",
    "print('finished')\n",
    "\n",
    "\"\"\"END SIMPLIFIED MODEL CHARACTERIZING\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Demonstrate Graphing Capabilites \n",
    "Combines the GraphDemonstration graphs for a single sample\n",
    "\"\"\"\n",
    "\n",
    "#Get 6 Graphs corresponding to the simulated user input\n",
    "figs = getGraphs(UserInput)\n",
    "\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs[3].savefig(\"FFT.jpg\", dpi='figure', facecolor='w', edgecolor='w',\n",
    "        orientation='portrait', papertype=None, format=None,\n",
    "        transparent=False, bbox_inches='tight', pad_inches=0.0,\n",
    "        frameon=None, metadata=None)\n",
    "figs[4].savefig(\"PSD.jpg\", dpi='figure', facecolor='w', edgecolor='w',\n",
    "        orientation='portrait', papertype=None, format=None,\n",
    "        transparent=False, bbox_inches='tight', pad_inches=0.0,\n",
    "        frameon=None, metadata=None)\n",
    "figs[5].savefig(\"AutoCorr.jpg\", dpi='figure', facecolor='w', edgecolor='w',\n",
    "        orientation='portrait', papertype=None, format=None,\n",
    "        transparent=False, bbox_inches='tight', pad_inches=0.0,\n",
    "        frameon=None, metadata=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Demonstration of the Dependence of RMS\"\n",
    "\n",
    "#read the training file\n",
    "filename = 'NotNormalized.csv'\n",
    "dataset = pd.read_csv(filename,header = 0,index_col = 0)\n",
    "\n",
    "#Plot the rms of each bearing\n",
    "figs = []\n",
    "figs.append(getPlot(dataset.index[0:2155],dataset[\"RMS\"][0:2155].values,\"Sample # (Bearing 1, X)\",\"RMS\",\"RMS\"))\n",
    "figs.append(getPlot(dataset.index[2156:4311],dataset[\"RMS\"][2156:4311].values,\"Sample # (Bearing 1, Y)\",\"RMS\",\"RMS\"))\n",
    "figs.append(getPlot(dataset.index[4312:6467],dataset[\"RMS\"][4312:6467].values,\"Sample # (Bearing 2, X)\",\"RMS\",\"RMS\"))\n",
    "figs.append(getPlot(dataset.index[6468:8623],dataset[\"RMS\"][6468:8623].values,\"Sample # (Bearing 2, Y)\",\"RMS\",\"RMS\"))\n",
    "figs.append(getPlot(dataset.index[8624:10779],dataset[\"RMS\"][8624:10779].values,\"Sample # (Bearing 3, X)\",\"RMS\",\"RMS\"))\n",
    "figs.append(getPlot(dataset.index[10780:12935],dataset[\"RMS\"][10780:12935].values,\"Sample # (Bearing 3, Y)\",\"RMS\",\"RMS\"))\n",
    "figs.append(getPlot(dataset.index[12936:15091],dataset[\"RMS\"][12936:15091].values,\"Sample # (Bearing 4, X)\",\"RMS\",\"RMS\"))\n",
    "figs.append(getPlot(dataset.index[15092:17247],dataset[\"RMS\"][15092:17247].values,\"Sample # (Bearing 4, Y)\",\"RMS\",\"RMS\"))\n",
    "\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
