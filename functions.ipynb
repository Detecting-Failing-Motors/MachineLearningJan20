{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "from scipy.signal import welch\n",
    "from detect_peaks import detect_peaks\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "import matplotlib.backends.backend_pdf\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateIMSDictionary(FileOfInterest,TrainingDataFile,HomeDirectory):\n",
    "    \"\"\"\n",
    "    returns UserInput - Dictionary of relevant info (see UserInputs2WorkingForm)\n",
    "    \n",
    "    GenerateIMSDictionary(\n",
    "        FileOfInterest - File name a single IMS file\n",
    "        TrainingDataFile - File name of TrainingDataFile\n",
    "        HomeDirectory - Directory with training file \n",
    "    )\n",
    "    \n",
    "    Example:\n",
    "        n = 2000 / 60\n",
    "        N = 16\n",
    "        Bd = 0.331*254\n",
    "        Pd = 2.815*254\n",
    "        phi = 15.17 * np.pi / 180\n",
    "        SampleFrequency = 20000\n",
    "        FileName = FileOfInterest\n",
    "        data = getIMSB1XData(FileName)\n",
    "        HomeDirectory = HomeDirectory\n",
    "        directory = os.listdir(HomeDirectory)\n",
    "        TrainingDataFile = TrainingDataFile\n",
    "        UserInput = UserInputs2WorkingForm(n,N,Bd,Pd,phi,SampleFrequency,FileName,data,HomeDirectory,directory,TrainingDataFile)\n",
    "\n",
    "    This is the same as: GenerateIMSDictionary('2003.10.22.12.06.24',\"TrainingData.csv\",os.getcwd())\n",
    "    \n",
    "    The Purpose of this function is quickly hardcode parameters that would be taken from the GUI.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Hardcoded Bearing Info\n",
    "    n = 2000 / 60    #Shaft rotational speed [Hz], n\n",
    "    N = 16  #No. of rolling elements [-], N\n",
    "    Bd = 0.331*254 #Diameter of a rolling element [mm], Bd\n",
    "    Pd = 2.815*254 #Pitch diameter [mm], Pd\n",
    "    phi = 15.17 * np.pi / 180 #Contact angle [rad], Phi\n",
    "    SampleFrequency = 20000 #Sampling Frequency\n",
    "    FileName = FileOfInterest #Filename in string format \n",
    "    data = getIMSB1XData(FileName) #Get the bearing 1: X direction from the filename\n",
    "    HomeDirectory = HomeDirectory #Homedirectory\n",
    "    directory = os.listdir(HomeDirectory) #Files HomeDirectory\n",
    "    TrainingDataFile = TrainingDataFile #String of File Name that is the Training file csv\n",
    "    UserInput = UserInputs2WorkingForm(n,N,Bd,Pd,phi,SampleFrequency,FileName,data,HomeDirectory,directory,TrainingDataFile)\n",
    "\n",
    "    return UserInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UserInputs2WorkingForm(n,N,Bd,Pd,phi,SampleFrequency,FileName,RawData,HomeDirectory,directory,TrainingDataFile):\n",
    "    \"\"\"\n",
    "    Returns a dictionary of relevant file information\n",
    "    \n",
    "    UserInputs2WorkingForm(\n",
    "        n - Shaft rotational speed [Hz], n\n",
    "        N - No. of rolling elements [-], N\n",
    "        Bd - Diameter of a rolling element [mm], Bd\n",
    "        Pd - Pitch diameter [mm], Pd\n",
    "        phi - Contact angle [rad], Phi\n",
    "        SampleFrequecy - SampleFrequency,\n",
    "        FileName - Title of file containing the raw data,\n",
    "        RawData - Array containing the raw data\n",
    "        HomeDirectory - Location of the Current Directory\n",
    "        directory - Directory of the FileOfInterest\n",
    "        TrainingDataFile - Title of CSV containg the training data for the machine learning\n",
    "        )\n",
    "        \n",
    "    This functions serves to take all relevant motor characteristics and puts them in a \n",
    "    dictionary.\n",
    "    This dictionary will serve as the building blocks for the rest of the functions.\n",
    "    \"\"\"\n",
    "    #Get Extra Info\n",
    "    NumberOfSamples = len(RawData)\n",
    "    dt = 1/SampleFrequency\n",
    "    Tmax = dt*NumberOfSamples\n",
    "    \n",
    "    #Arrange\n",
    "    x = {\n",
    "        'n': n, #Shaft rotational speed [Hz], n\n",
    "        'N': N, #No. of rolling elements [-], N\n",
    "        'Bd': Bd, #Diameter of a rolling element [mm], Bd\n",
    "        'Pd': Pd, #Pitch diameter [mm], Pd\n",
    "        'Phi': phi, #Contact angle [rad], Phi\n",
    "        'Sampling Frequency': SampleFrequency,\n",
    "        'Time of Sampling': Tmax,\n",
    "        'Number of Samples': NumberOfSamples,\n",
    "        'File of Interest': FileName,\n",
    "        'HomeDirectory': HomeDirectory,\n",
    "        'Working Directory': directory,\n",
    "        'TrainingFileName': TrainingDataFile,\n",
    "        'Signal Data of Interest': RawData   \n",
    "    }\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIMSB1XData(FileOfInterest):\n",
    "    \"\"\"\n",
    "    Returns an 1-D array of IMS data\n",
    "    \n",
    "    Subfunction for UserInputs2WorkingForm\n",
    "    getIMSB1XData(\n",
    "        FileOfInterest - Title of file containing the raw data from the IMS dataset\n",
    "    )\n",
    "    This function reads the IMS bearing dataset for set 1 that was taken from:\n",
    "    http://data-acoustics.com/measurements/bearing-faults/bearing-4/\n",
    "    \"\"\"\n",
    "    #Get Data\n",
    "    data = pd.read_table(FileOfInterest,header = None)\n",
    "    data.columns = ['b1x','b1y','b2x','b2y','b3x','b3y','b4x','b4y']\n",
    "    return np.transpose(data.values[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getValuesFromRawData(filename):\n",
    "    \"\"\"\n",
    "    Returns time, amp (tuple) which are both arrays of floats\n",
    "    \n",
    "    getValuesFromRawData(\n",
    "        filename - Name of file containing raw data \n",
    "        )\n",
    "    \n",
    "    This functions get the time and amplitude from the Raw data from the microcontroller\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read Data\n",
    "    dataset = pd.read_csv(filename, header = None, index_col = False)\n",
    "    dataset.rename(columns={0: \"Time\", 1: \"Value\"}, inplace = True)\n",
    "\n",
    "    #Prepare Raw Data\n",
    "    i = 0\n",
    "    \n",
    "    #Instantiate\n",
    "    time = []\n",
    "    amp = []\n",
    "    \n",
    "    \n",
    "    while i < len(dataset['Time'].values):\n",
    "        i += 1\n",
    "        \n",
    "        #Break when seeing the end line of 0 0 \n",
    "        #Else append\n",
    "        if dataset['Time'].values[i] == 0 and dataset['Value'].values[i] == 0:\n",
    "            break\n",
    "        else:\n",
    "            time.append(dataset['Time'].values[i])\n",
    "            amp.append(dataset['Value'].values[i])\n",
    "            \n",
    "    return time,amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReplaceSignalDataofInterest(Data,UserInput,filename):\n",
    "    \"\"\"\n",
    "    Returns a dictionary of relevant file information\n",
    "    \n",
    "    UserInputs2WorkingForm(\n",
    "        Data - This is the actual data\n",
    "        UserInput - UserInput - Dictionary of relevant info (see UserInputs2WorkingForm)\n",
    "        filename - \n",
    "        )\n",
    "        \n",
    "    This functions replaces the signal data of interest value along with the file name of a dictionary.\n",
    "    This function was created to \"cheat\" the system and allow the generation of training data \n",
    "    by manually inputting the actual data. This helps becuase right now the GetIMSB1XData() function\n",
    "    only gets B1X column for simplicity.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Copy\n",
    "    x = UserInput.copy()\n",
    "    \n",
    "    #Replace\n",
    "    x['Signal Data of Interest'] = Data \n",
    "    x['File of Interest'] = filename\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BearingInfomation(UserInput):\n",
    "    \"\"\"\n",
    "    Returns a dictionary with Bearing Characteristic Frequencies\n",
    "    \n",
    "    BearingInfomation(\n",
    "        UserInput - Dictionary of relevant info (see UserInputs2WorkingForm)\n",
    "        )\n",
    "        \n",
    "    This functions calculates the bearing characteristic frequencies\n",
    "    \"\"\"\n",
    "    #Get Needed Info\n",
    "    n = UserInput['n']\n",
    "    N = UserInput['N']\n",
    "    Bd = UserInput['Bd']\n",
    "    Pd = UserInput['Pd']\n",
    "    phi = UserInput['Phi']\n",
    "    \n",
    "    #Calculate Bearing Frequncies using known equations\n",
    "    xx = Bd/Pd*np.cos(phi)\n",
    "    BPFI = (N/2)*(1 + xx)*n\n",
    "    BPFO = (N/2)*(1 - xx)*n\n",
    "    BSF = (Pd/(2*Bd))*(1-(xx)**2)*n\n",
    "    FTF= (1/2)*(1 - xx)*n\n",
    "    \n",
    "    #Arrange\n",
    "    x = {\n",
    "        \"BPFI\": BPFI,\n",
    "        \"BPFO\": BPFO,\n",
    "        \"BSF\":  BSF,\n",
    "        \"FTF\":  FTF\n",
    "    }\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemoveDCOffset(UserInput):\n",
    "    \"\"\"\n",
    "    Returns a modified dictionary\n",
    "    \n",
    "    RemoveDCOffset(\n",
    "        UserInput - Dictionary of relevant info (see UserInputs2WorkingForm)\n",
    "        )\n",
    "        \n",
    "    This functions removes the dc bias from the signal in the UserInput dictionary\n",
    "    \"\"\"\n",
    "    #Copy\n",
    "    temp = UserInput.copy()\n",
    "    \n",
    "    #Modify\n",
    "    temp[\"Signal Data of Interest\"] = temp[\"Signal Data of Interest\"] - np.mean(temp[\"Signal Data of Interest\"])\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FourierTransform(UserInput):\n",
    "    \"\"\"\n",
    "    Returns a dictionary what contains the frequency and frequency amplitude arrays\n",
    "    \n",
    "    FourierTransform(\n",
    "        UserInput - Dictionary of relevant info (see UserInputs2WorkingForm)\n",
    "    )\n",
    "    \n",
    "    The functions perfroms fast fourier transform on the UserInput Signal \n",
    "    Data of Interest\n",
    "    \"\"\"\n",
    "\n",
    "    #Get Needed Info\n",
    "    sig = UserInput['Signal Data of Interest']\n",
    "    NumberOfSamples = UserInput['Number of Samples']\n",
    "    Tmax = UserInput['Time of Sampling']\n",
    "    \n",
    "    #Fourier Transform\n",
    "    frq = np.arange(NumberOfSamples)/(Tmax)# two sides frequency range\n",
    "    frq = frq[range(int(NumberOfSamples/(2)))] # one side frequency range\n",
    "    Y = abs(np.fft.fft(sig))/NumberOfSamples # fft computing and normalization\n",
    "    Y = Y[range(int(NumberOfSamples/2))]\n",
    "    \n",
    "    #Arrange\n",
    "    x = {\n",
    "        \"Frequency\":frq,\n",
    "        \"Freq. Amp.\": Y\n",
    "        }\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_psd_values(UserInput):\n",
    "    \"\"\"\n",
    "    Returns a dictionary that contains the frequency and the frequency amplitude arrays\n",
    "    \n",
    "    get_psd_values(\n",
    "        UserInput - Dictionary of relevant info (see UserInputs2WorkingForm)\n",
    "    )\n",
    "    \n",
    "    The functions perfroms power spectrum density on the UserInput Signal \n",
    "    Data of Interest\n",
    "    \"\"\"\n",
    "    #Get Needed Info\n",
    "    sig = UserInput['Signal Data of Interest']\n",
    "    SamplingFrequency = UserInput['Sampling Frequency']\n",
    "    \n",
    "    #Perfrom psd\n",
    "    frq, psd_values = welch(sig, fs=SamplingFrequency)\n",
    "    \n",
    "    #Arrange\n",
    "    x = {\n",
    "        \"Frequency\":frq,\n",
    "        \"PSD\": psd_values\n",
    "        }\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorr(x):\n",
    "    \"\"\"\n",
    "    Taken from:\n",
    "    https://ipython-books.github.io/103-computing-the-autocorrelation-of-a-time-series/\n",
    "    \n",
    "    Returns the autocorrelation of the signal x\n",
    "    \n",
    "    autocorr(\n",
    "        x - signal of interest\n",
    "        )\n",
    "    \n",
    "    This functions performs correlation\n",
    "    \"\"\"\n",
    "    result = np.correlate(x, x, mode='full')\n",
    "    return result[len(result)//2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_autocorr_values(UserInput):\n",
    "    \"\"\"\n",
    "    Modified from: \n",
    "    https://ipython-books.github.io/103-computing-the-autocorrelation-of-a-time-series/\n",
    "    \n",
    "    Returns a dictionary\n",
    "    \n",
    "    get_autocorr_values(\n",
    "        UserInput - Dictionary of relevant info (see UserInputs2WorkingForm)\n",
    "    )\n",
    "    \n",
    "    The functions perfroms autocorrelation on the UserInput Signal \n",
    "    Data of Interest\n",
    "    \"\"\"\n",
    "    #Get needed info\n",
    "    sig = UserInput['Signal Data of Interest']\n",
    "    Tmax = UserInput['Time of Sampling']\n",
    "    N = UserInput['Number of Samples']\n",
    "    \n",
    "    #Call correlation function\n",
    "    autocorr_values = autocorr(sig)\n",
    "    \n",
    "    #Arrange\n",
    "    x_values = np.array([Tmax * jj for jj in range(0, N)])\n",
    "    x = {\n",
    "        \"X Values\":x_values,\n",
    "        \"Autocorr Values\": autocorr_values\n",
    "        }\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TimeDomainInformation(UserInput):\n",
    "    \"\"\"\n",
    "    Returns a dictionary with Time Domain Characteristics\n",
    "    \n",
    "    TimeDomainInformation(\n",
    "        UserInput - Dictionary of relevant info (see UserInputs2WorkingForm)\n",
    "        )\n",
    "        \n",
    "    This functions calculates the Time Domain Characteristics\n",
    "    \"\"\"\n",
    "    #Get Needed Info\n",
    "    sig = UserInput['Signal Data of Interest']\n",
    "    \n",
    "    #Arrange\n",
    "    x = {\n",
    "        \"RMS\": np.mean(sig**2),\n",
    "        \"STD\": np.std(sig),\n",
    "        \"Mean\": np.mean(sig),\n",
    "        \"Max\": np.max(sig),\n",
    "        \"Min\": np.min(sig),\n",
    "        \"Peak-to-Peak\": (np.max(sig) - np.min(sig)),\n",
    "        \"Max ABS\": np.max(abs(sig)),\n",
    "        \"Kurtosis\": kurtosis(sig),\n",
    "        \"Skew\": skew(sig),\n",
    "    }\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Magnitude(Y):\n",
    "    \"\"\"\n",
    "    Returns a float that is the magnitude of the array Y\n",
    "    \n",
    "    Magnitude(\n",
    "     Y - an array of numbers to get the magnitude\n",
    "    )\n",
    "    \"\"\"\n",
    "    \n",
    "    #Square\n",
    "    mag = 0\n",
    "    for i in range(0,len(Y)):\n",
    "        mag = mag + Y[i]**2\n",
    "        \n",
    "    #Square Root\n",
    "    mag = mag ** 0.5\n",
    "    \n",
    "    return mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalize(UserInput):\n",
    "    \"\"\"\n",
    "    Returns a dictionary\n",
    "    \n",
    "    Normalize(\n",
    "        UserInput - Dictionary of relevant info (see UserInputs2WorkingForm)\n",
    "    )\n",
    "    \"\"\"\n",
    "    \n",
    "    #Copy\n",
    "    x = UserInput.copy()\n",
    "    \n",
    "    #Get Magnitude\n",
    "    mag = Magnitude(x['Signal Data of Interest'])\n",
    "    \n",
    "    #Normalize\n",
    "    x['Signal Data of Interest'] = x['Signal Data of Interest'] / mag\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PosMagnitude(Y):\n",
    "    \"\"\"\n",
    "    Returns a float that is the Posmagnitude of the array Y\n",
    "    \n",
    "    Magnitude(\n",
    "     Y - an array of numbers to get the magnitude\n",
    "    )\n",
    "    \n",
    "    Get the magnitude of all numbers greater than 0\n",
    "    \"\"\"\n",
    "    \n",
    "    #Square if positive\n",
    "    mag = 0\n",
    "    for i in range(0,len(Y)):\n",
    "        if Y[i] > 0:\n",
    "            mag = mag + Y[i]**2\n",
    "            \n",
    "    #Square Root\n",
    "    mag = mag ** 0.5\n",
    "    \n",
    "    return mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPeaks(X,Y,xlabel,ylabel,Title):\n",
    "    \"\"\"\n",
    "    Returns a figure\n",
    "    \n",
    "    plotPeaks(\n",
    "        X - Independent data array\n",
    "        Y - Dependent data array\n",
    "        xlabel - string for the x-axis label\n",
    "        ylabel - string for the y-axis label\n",
    "        Title - string the the Title\n",
    "    )\n",
    "    \n",
    "    This function plots the data with the peaks indicated\n",
    "    \"\"\"\n",
    "    #Set Parameters\n",
    "    Ymag = PosMagnitude(Y)\n",
    "    Ynew = Y/Ymag\n",
    "    min_peak_height = .04\n",
    "    threshold = 0.15*np.std(Ynew)\n",
    "    \n",
    "    #Get indices of peak\n",
    "    peak = detect_peaks(Ynew,edge = 'rising',mph = min_peak_height, mpd = 5, threshold = threshold )\n",
    "    \n",
    "    #Plot base figure\n",
    "    fig = plt.figure()\n",
    "    plt.plot(X,Y)\n",
    "\n",
    "    #Plot Scatter\n",
    "    for i in peak:\n",
    "       plt.scatter(X[i],Y[i], c= 'r', marker='*',s = 80)\n",
    "    \n",
    "    #Set Graph Features\n",
    "    plt.xlabel(xlabel, fontsize=12)\n",
    "    plt.ylabel(ylabel, fontsize=12)\n",
    "    plt.title(Title)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSortedPeak(X,Y):\n",
    "    \"\"\"\n",
    "    SubFunction for FrequencyDomainInformation\n",
    "    \n",
    "    Returns Amplitude of Y, Loctation\n",
    "    \n",
    "    GetSortedPeak(\n",
    "        X - Independent Variable\n",
    "        Y - Dependent Variable\n",
    "        )\n",
    "        \n",
    "    Uses detect_peaks function taken from Github:\n",
    "    __author__ = \"Marcos Duarte, https://github.com/demotu/BMC\"\n",
    "    \n",
    "    Get the indices of relevant peaks\n",
    "    Then Returns the amplitude,location of the relevant peaks\n",
    "    \"\"\"\n",
    "    #Original\n",
    "    \"\"\"\n",
    "    #Set Parameters\n",
    "    min_peak_height = 0.1 * np.nanmax(Y) #Original\n",
    "    threshold = 0.05 * np.nanmax(Y) #Original\n",
    "    \n",
    "    #Get indices of peak\n",
    "    peak = detect_peaks(Y,edge = 'rising',mph = min_peak_height, mpd = 2, threshold = threshold ) #Original\n",
    "    \"\"\"\n",
    "    #NEW\n",
    "    #Set Parameters\n",
    "    Ymag = PosMagnitude(Y)\n",
    "    Ynew = Y/Ymag\n",
    "    min_peak_height = .04\n",
    "    threshold = 0.15*np.std(Ynew)\n",
    "    \n",
    "    #Get indices of peak\n",
    "    peak = detect_peaks(Ynew,edge = 'rising',mph = min_peak_height, mpd = 5, threshold = threshold )\n",
    "    \n",
    "    #Get values corresponding to indices \n",
    "    m = []\n",
    "    mm = []\n",
    "    for i in peak:\n",
    "        m.append(Y[i]) \n",
    "        mm.append(X[i])\n",
    "\n",
    "    #Sort arcording to the amplitude\n",
    "    mmm = np.argsort(m)\n",
    "    n = []\n",
    "    nn = []\n",
    "    for i in mmm:\n",
    "        n.append(m[i])\n",
    "        nn.append(mm[i])\n",
    "    \n",
    "    #Sort in Descending Amplitdue while keeping locations matched\n",
    "    n  = n[::-1] #amplitude\n",
    "    nn = nn[::-1] #location\n",
    "    \n",
    "    #Arrange\n",
    "    return n, nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FrequencyDomainInformation(UserInput):\n",
    "    \"\"\"\n",
    "    Returns a dictionary with Frequency Domain Characteristics\n",
    "    Top 5 frequncy and amplitudes for:\n",
    "    fft\n",
    "    psd\n",
    "    correlation\n",
    "    \n",
    "    FrequencyDomainInformation(\n",
    "        UserInput - Dictionary of relevant info (see UserInputs2WorkingForm)\n",
    "        )\n",
    "        \n",
    "    Note: 77777 refers to a blank cell\n",
    "        We had to fill in blank cells to work with pandas dataframe\n",
    "    \"\"\"\n",
    "    #Call FFT, PSD, and Correlation Values\n",
    "    x1 = FourierTransform(UserInput)\n",
    "    x2 = get_psd_values(UserInput)\n",
    "    x3 = get_autocorr_values(UserInput)\n",
    "    FTamp,FTfreq = GetSortedPeak(x1['Frequency'],x1['Freq. Amp.'])\n",
    "    PSDamp,PSDfreq = GetSortedPeak(x2['Frequency'],x2['PSD'])\n",
    "    Cor,CorTime = GetSortedPeak(x3['X Values'],x3['Autocorr Values'])\n",
    "\n",
    "    #Originally -999 \n",
    "    #Now 77777\n",
    "    #Take Care of Empty Values\n",
    "    while len(FTamp) <= 5:\n",
    "        FTamp.append(['77777'])\n",
    "    while len(FTfreq) <= 5:\n",
    "        FTfreq.append(['77777'])\n",
    "    while len(PSDamp) <= 5:\n",
    "        PSDamp.append(['77777'])\n",
    "    while len(PSDfreq) <= 5:\n",
    "        PSDfreq.append(['77777'])\n",
    "    while len(Cor) <= 5:\n",
    "        Cor.append(['77777'])\n",
    "    while len(CorTime) <= 5:\n",
    "        CorTime.append(['77777'])\n",
    "    \n",
    "    #Arrange\n",
    "    x = {\n",
    "        \"FFT Frq @ Peak 1\": FTfreq[0],\n",
    "        \"FFT Frq @ Peak 2\": FTfreq[1],\n",
    "        \"FFT Frq @ Peak 3\": FTfreq[2],\n",
    "        \"FFT Frq @ Peak 4\": FTfreq[3],\n",
    "        \"FFT Frq @ Peak 5\": FTfreq[4],\n",
    "        \"FFT Amp @ Peak 1\": FTamp[0],\n",
    "        \"FFT Amp @ Peak 2\": FTamp[1],\n",
    "        \"FFT Amp @ Peak 3\": FTamp[2],\n",
    "        \"FFT Amp @ Peak 4\": FTamp[3],\n",
    "        \"FFT Amp @ Peak 5\": FTamp[4],\n",
    "        \"PSD Frq @ Peak 1\": PSDfreq[0],\n",
    "        \"PSD Frq @ Peak 2\": PSDfreq[1],\n",
    "        \"PSD Frq @ Peak 3\": PSDfreq[2],\n",
    "        \"PSD Frq @ Peak 4\": PSDfreq[3],\n",
    "        \"PSD Frq @ Peak 5\": PSDfreq[4],\n",
    "        \"PSD Amp @ Peak 1\": PSDamp[0],\n",
    "        \"PSD Amp @ Peak 2\": PSDamp[1],\n",
    "        \"PSD Amp @ Peak 3\": PSDamp[2],\n",
    "        \"PSD Amp @ Peak 4\": PSDamp[3],\n",
    "        \"PSD Amp @ Peak 5\": PSDamp[4],\n",
    "        \"Autocorrelate Time @ Peak 1\": CorTime[0],\n",
    "        \"Autocorrelate Time @ Peak 2\": CorTime[1],\n",
    "        \"Autocorrelate Time @ Peak 3\": CorTime[2],\n",
    "        \"Autocorrelate Time @ Peak 4\": CorTime[3],\n",
    "        \"Autocorrelate Time @ Peak 5\": CorTime[4],\n",
    "        \"Autocorrelate @ Peak 1\": Cor[0],\n",
    "        \"Autocorrelate @ Peak 2\": Cor[1],\n",
    "        \"Autocorrelate @ Peak 3\": Cor[2],\n",
    "        \"Autocorrelate @ Peak 4\": Cor[3],\n",
    "        \"Autocorrelate @ Peak 5\": Cor[4]\n",
    "    }\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAbsoluteTime(file):\n",
    "    \"\"\"\n",
    "    Subfunction for StateInformation\n",
    "    \n",
    "    Returns the \"magnitude\" of the time stamp \n",
    "    \n",
    "    getAbsolutTime(\n",
    "        file - file name that has bearing information within it\n",
    "        )\n",
    "    \n",
    "    This function computes the magnitude of time when the IMS data was taken \n",
    "    \"\"\"\n",
    "    #Get needed info\n",
    "    year   = int(file[0:4])\n",
    "    month  = int(file[5:7])\n",
    "    day    = int(file[8:10])\n",
    "    hour   = int(file[11:13])\n",
    "    minute = int(file[14:16])\n",
    "    second = int(file[17:19])\n",
    "    \n",
    "    #Compute starting from the 10 month\n",
    "    #in seconds don't include years taking 10 as the start month\n",
    "    x = second + 60*minute + 60*60*hour + 24*60*60*day + 31*24*60*60*(month - 10)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "http://mkalikatzarakis.eu/wp-content/uploads/2018/12/IMS_dset.html\n",
    "Previous work done on this dataset states that seven different states of health were observed:\n",
    "\n",
    "Early (initial run-in of the bearings)\n",
    "Normal\n",
    "Suspect (the health seems to be deteriorating)\n",
    "Imminent failure (for bearings 1 and 2, which didnâ€™t actually fail, but were severely worn out)\n",
    "Inner race failure (bearing 3)\n",
    "Rolling element failure (bearing 4)\n",
    "Stage 2 failure (bearing 4)\n",
    "For the first test (the one we are working on), the following labels have been proposed per file:\n",
    "\n",
    "Bearing 1\n",
    "early: 2003.10.22.12.06.24 - 2013.10.23.09.14.13\n",
    "suspect: 2013.10.23.09.24.13 - 2003.11.08.12.11.44 (bearing 1 was in suspicious health from the beginning, but showed some self-healing effects)\n",
    "normal: 2003.11.08.12.21.44 - 2003.11.19.21.06.07\n",
    "suspect: 2003.11.19.21.16.07 - 2003.11.24.20.47.32\n",
    "imminent failure: 2003.11.24.20.57.32 - 2003.11.25.23.39.56\n",
    "\n",
    "Bearing 2\n",
    "early: 2003.10.22.12.06.24 - 2003.11.01.21.41.44\n",
    "normal: 2003.11.01.21.51.44 - 2003.11.24.01.01.24\n",
    "suspect: 2003.11.24.01.11.24 - 2003.11.25.10.47.32\n",
    "imminent failure: 2003.11.25.10.57.32 - 2003.11.25.23.39.56\n",
    "\n",
    "Bearing 3\n",
    "early: 2003.10.22.12.06.24 - 2003.11.01.21.41.44\n",
    "normal: 2003.11.01.21.51.44 - 2003.11.22.09.16.56\n",
    "suspect: 2003.11.22.09.26.56 - 2003.11.25.10.47.32\n",
    "Inner race failure: 2003.11.25.10.57.32 - 2003.11.25.23.39.56\n",
    "\n",
    "Bearing 4\n",
    "early: 2003.10.22.12.06.24 - 2003.10.29.21.39.46\n",
    "normal: 2003.10.29.21.49.46 - 2003.11.15.05.08.46\n",
    "suspect: 2003.11.15.05.18.46 - 2003.11.18.19.12.30\n",
    "Rolling element failure: 2003.11.19.09.06.09 - 2003.11.22.17.36.56\n",
    "Stage 2 failure: 2003.11.22.17.46.56 - 2003.11.25.23.39.56\n",
    "\"\"\"\n",
    "\n",
    "def StateInformation(UserInput,BearingNum):\n",
    "    \"\"\"\n",
    "    Returns a Dictionary of a Bearing State\n",
    "    \n",
    "    StateInformation(\n",
    "        UserInput - Dictionary of relevant info (see UserInputs2WorkingForm)\n",
    "        BearingNum - Bearing Num to know which failure type\n",
    "        )\n",
    "    \n",
    "    This function is used to generate a known outcome for the training data.\n",
    "    This function is only intended to aid in generating the training data.\n",
    "    \"\"\"\n",
    "    #Get Needed Info \n",
    "    file = UserInput['File of Interest']\n",
    "    \n",
    "    #Comput time for comarison\n",
    "    absolutetime = getAbsoluteTime(file)\n",
    "    \n",
    "    #Transitions according to the above comments\n",
    "    #Bearing 1 transitions\n",
    "    b1e2s  = getAbsoluteTime(\"2013.10.23.09.14.13\")\n",
    "    b1s2n  = getAbsoluteTime(\"2003.11.08.12.11.44\")\n",
    "    b1n2s  = getAbsoluteTime(\"2003.11.19.21.06.07\")\n",
    "    b1s2i  = getAbsoluteTime(\"2003.11.24.20.47.32\")\n",
    "    \n",
    "    #Bearing 2 transitions\n",
    "    b2e2n  = getAbsoluteTime(\"2003.11.01.21.41.44\")\n",
    "    b2n2s  = getAbsoluteTime(\"2003.11.24.01.01.24\")\n",
    "    b2s2i  = getAbsoluteTime(\"2003.11.25.10.47.32\")\n",
    "    \n",
    "    #Bearing 3 transitions\n",
    "    b3e2n  = getAbsoluteTime(\"2003.11.01.21.41.44\")\n",
    "    b3n2s  = getAbsoluteTime(\"2003.11.22.09.16.56\")\n",
    "    b3s2irf  = getAbsoluteTime(\"2003.11.25.10.47.32\")\n",
    "    \n",
    "    #Bearing 4 transitions\n",
    "    b4e2n  = getAbsoluteTime(\"2003.10.29.21.39.46\")\n",
    "    b4n2s  = getAbsoluteTime(\"2003.11.15.05.08.46\")\n",
    "    b4s2r  = getAbsoluteTime(\"2003.11.18.19.12.30\")\n",
    "    b4r2f  = getAbsoluteTime(\"2003.11.22.17.36.56\")\n",
    "    \n",
    "    #Get state / output error if no state possible\n",
    "    m = \"ERROR\"\n",
    "    if BearingNum == 1:\n",
    "        if absolutetime   <= b1e2s:\n",
    "            m = \"Early\"\n",
    "        elif absolutetime <= b1s2n:\n",
    "            m = \"Suspect\"\n",
    "        elif absolutetime <= b1n2s:\n",
    "            m = \"Normal\"\n",
    "        elif absolutetime <= b1s2i:\n",
    "            m = \"Suspect\"\n",
    "        elif absolutetime > b1s2i:\n",
    "            m = \"Imminent Failure\"\n",
    "    elif BearingNum == 2:\n",
    "        if absolutetime   <= b2e2n:\n",
    "            m = \"Early\"\n",
    "        elif absolutetime <= b2n2s:\n",
    "            m = \"Normal\"\n",
    "        elif absolutetime <= b2s2i:\n",
    "            m = \"Suspect\"\n",
    "        elif absolutetime > b2s2i:\n",
    "            m = \"Imminent Failure\" \n",
    "    elif BearingNum == 3:\n",
    "        if absolutetime   <= b3e2n:\n",
    "            m = \"Early\"\n",
    "        elif absolutetime <= b3n2s:\n",
    "            m = \"Normal\"\n",
    "        elif absolutetime <= b3s2irf:\n",
    "            m = \"Suspect\"\n",
    "        elif absolutetime >= b3s2irf:\n",
    "            m = \"Inner Race Failure\"   \n",
    "    elif BearingNum == 4:\n",
    "        if absolutetime   <= b4e2n:\n",
    "            m = \"Early\"\n",
    "        elif absolutetime <= b4n2s:\n",
    "            m = \"Normal\"\n",
    "        elif absolutetime <= b4s2r:\n",
    "            m = \"Suspect\"\n",
    "        elif absolutetime <= b4r2f:\n",
    "            m = \"Rolling Element Failure\"\n",
    "        elif absolutetime > b4r2f:\n",
    "            m = \"Stage 2 Failure\"\n",
    "    else:\n",
    "        m = \"ERROR\"\n",
    "    \n",
    "    #NOT in the original model\n",
    "    State2Int = StateDict()\n",
    "    \n",
    "    #Arrange\n",
    "    x = {\n",
    "        \"State\": State2Int[m]\n",
    "    }\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MotorInformation(UserInput):\n",
    "    \"\"\"\n",
    "    Returns a Dictionary containg motor characteristics used in the IMS dataset\n",
    "    \n",
    "    MotorInformation(\n",
    "        UserInput - Dictionary of relevant info (see UserInputs2WorkingForm)\n",
    "        )\n",
    "        \n",
    "    Only valid for IMS dataset\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    WILL NEED TO BE UPDATED GOING FORWARD\n",
    "    \"\"\"\n",
    "    x = {\n",
    "        \"Motor Type AC(1)-DC(0)\": 1,\n",
    "        \"Shaft Speed [Hz]\": 2000/60\n",
    "    }\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCompleteDataFrame(UserInput,BearingNum):\n",
    "    \"\"\"\n",
    "    Returns a Dataframe for sample\n",
    "    \n",
    "    getCompleteDataFrame(\n",
    "        UserInput - Dictionary of relevant info (see UserInputs2WorkingForm)\n",
    "        BearingNum - Bearing Num to know which failure type\n",
    "        )\n",
    "    \n",
    "    This function is used to generate a known outcome for the training data.\n",
    "    This function is only intended to aid in generating the training data.\n",
    "    \"\"\"\n",
    "    #Call specific function order for consistency \n",
    "    UserInput1 = UserInput.copy()\n",
    "    UserInput2 = RemoveDCOffset(UserInput1)\n",
    "    UserInput3 = Normalize(UserInput2)\n",
    "    BearingInfo = BearingInfomation(UserInput3)\n",
    "    TimeDomainInfo = TimeDomainInformation(UserInput3)\n",
    "    FrequecyDomainInfo = FrequencyDomainInformation(UserInput3)\n",
    "    StateInfo = StateInformation(UserInput3,BearingNum)\n",
    "    MotorInfo = MotorInformation(UserInput3)\n",
    "    \n",
    "    #Arrange\n",
    "    Features = {**StateInfo,**MotorInfo,**BearingInfo,**TimeDomainInfo,**FrequecyDomainInfo}\n",
    "    Features = pd.DataFrame(Features, index=[0])\n",
    "    return Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTESTDataFrame(UserInput):\n",
    "    \"\"\"\n",
    "    Returns a Dataframe that does not need the state\n",
    "    \n",
    "    getTESTDataFrame(\n",
    "        UserInput - Dictionary of relevant info (see UserInputs2WorkingForm)\n",
    "        )\n",
    "    \n",
    "    This function generates a dataframe without knowing its state\n",
    "    This function calls functions in the consistent order\n",
    "    \"\"\"\n",
    "    #Call specific function order for consistency \n",
    "    UserInput1 = UserInput.copy()\n",
    "    UserInput2 = RemoveDCOffset(UserInput1)\n",
    "    UserInput3 = Normalize(UserInput2)\n",
    "    BearingInfo = BearingInfomation(UserInput3)\n",
    "    TimeDomainInfo = TimeDomainInformation(UserInput3)\n",
    "    FrequecyDomainInfo = FrequencyDomainInformation(UserInput3)\n",
    "    MotorInfo = MotorInformation(UserInput3)\n",
    "    \n",
    "    #Arrange (with no state info)\n",
    "    Features = {**MotorInfo,**BearingInfo,**TimeDomainInfo,**FrequecyDomainInfo}\n",
    "    Features = pd.DataFrame(Features, index=[0])\n",
    "    return Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTESTMatrix(UserInput):\n",
    "    \"\"\"\n",
    "    Returns an array that can be directly plugged into Predict()\n",
    "    \n",
    "    getTestMatrix(\n",
    "        UserInput - Dictionary of relevant info (see UserInputs2WorkingForm)\n",
    "    )\n",
    "    \"\"\"\n",
    "    \n",
    "    Features = getTESTDataFrame(UserInput)\n",
    "    \n",
    "    #Correct the type of data\n",
    "    return Features.values[:,0:(Features.shape[1]-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPlot(X,Y,xlabel,ylabel,Title):\n",
    "    \"\"\"\n",
    "    Subfunction of getGraphs\n",
    "    Returns a figure\n",
    "    \n",
    "    getPlot(\n",
    "        X - Data for independent variable\n",
    "        Y - Data for dependent variable\n",
    "        xlabel - X-axis label\n",
    "        ylabel - Y-axis label\n",
    "        Title - Title of figure\n",
    "        )\n",
    "    \n",
    "    Performs plt.plot\n",
    "    \"\"\"\n",
    "    \n",
    "    #Plot\n",
    "    fig = plt.figure()\n",
    "    plt.plot(X,Y,c = np.random.rand(3,))\n",
    "    plt.xlabel(xlabel, fontsize=12)\n",
    "    plt.ylabel(ylabel, fontsize=12)\n",
    "    plt.title(Title)\n",
    "    plt.grid(True)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGraphs(UserInput):\n",
    "    \"\"\"\n",
    "    Returns an array of figures\n",
    "    \n",
    "    getGraphs(\n",
    "        UserInput - Dictionary of relevant info (see UserInputs2WorkingForm)\n",
    "        )\n",
    "    \n",
    "    This function generates a figures for:\n",
    "    Raw time series\n",
    "    Time series with no DC offset\n",
    "    FFT\n",
    "    PSD\n",
    "    Correlation\n",
    "    \"\"\"\n",
    "    #Create time series array\n",
    "    t = np.arange(0,UserInput['Time of Sampling'],1/UserInput['Sampling Frequency'])\n",
    "    \n",
    "    #Perform FFT, PSD, Correlation, DC Offset\n",
    "    UserInput1 = RemoveDCOffset(UserInput)\n",
    "    UserInput2 = Normalize(UserInput1)\n",
    "    x1 = FourierTransform(UserInput2)\n",
    "    x2 = get_psd_values(UserInput2)\n",
    "    x3 = get_autocorr_values(UserInput2)\n",
    "    \n",
    "    \n",
    "    #Get Figures\n",
    "    figs = []\n",
    "    figs.append(getPlot(t,UserInput['Signal Data of Interest'],\"time (s)\",\"Amplitude\",\"Raw Data\"))\n",
    "    figs.append(getPlot(t,UserInput1['Signal Data of Interest'],\"time (s)\",\"Amplitude\",\"Raw Data w/ Removed DC Offset\"))\n",
    "    figs.append(getPlot(t,UserInput2['Signal Data of Interest'],\"time (s)\",\"Amplitude\",\"Normalized Raw Data\"))\n",
    "    figs.append(getPlot(x1['Frequency'],x1['Freq. Amp.'],'Frequency [Hz]',\"time (s)\",\"FFT\"))\n",
    "    figs.append(getPlot(x2['Frequency'],x2['PSD'],'Frequency [Hz]','PSD [V**2 / Hz]',\"PSD\"))\n",
    "    figs.append(getPlot(x3['X Values'],x3['Autocorr Values'],'time delay [s]',\"Autocorrelation amplitude\",\"Autocorrelation\"))\n",
    "\n",
    "    return figs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBarPlot(X,Y,xlabel,Title):\n",
    "    \"\"\"\n",
    "    Subfunction of getGraphs\n",
    "    Returns a figure\n",
    "    \n",
    "    getBarPlot(\n",
    "        X - Data for independent variable\n",
    "        Y - Data for dependent variable\n",
    "        xlabel - X-axis label\n",
    "\n",
    "        Title - Title of figure\n",
    "        )\n",
    "    \n",
    "    Performs plt.barh\n",
    "    \"\"\"\n",
    "    #Bar plot\n",
    "    fig = plt.figure()\n",
    "    y_pos = np.arange(len(Y))\n",
    "    plt.barh(y_pos, X, align='center')\n",
    "    plt.xlabel(xlabel, fontsize=12)\n",
    "    plt.yticks(y_pos, Y)\n",
    "    plt.title(Title)\n",
    "    plt.grid(True)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate(f, n):\n",
    "    '''https://stackoverflow.com/questions/783897/truncating-floats-in-python/51172324#51172324'''\n",
    "    '''Truncates/pads a float f to n decimal places without rounding'''\n",
    "    s = '{}'.format(f)\n",
    "    if 'e' in s or 'E' in s:\n",
    "        return '{0:.{1}f}'.format(f, n)\n",
    "    i, p, d = s.partition('.')\n",
    "    return '.'.join([i, (d+'0'*n)[:n]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSplitTrainingData(UserInput, seed = 6):\n",
    "    \"\"\"\n",
    "    Returns an X_train, X_test, Y_train, Y_test\n",
    "    \n",
    "    getGraphs(UserInput)\n",
    "        UserInput - Dictionary of relevant info (see UserInputs2WorkingForm)\n",
    "        seed - random number for splitting of test and trainig (default = 6)\n",
    "        )\n",
    "    \n",
    "    This returns the training and test sets\n",
    "    \"\"\"\n",
    "    \n",
    "    #Find training file name and read it\n",
    "    for file in UserInput['Working Directory']:\n",
    "        if file == UserInput['TrainingFileName']:\n",
    "            dataset = pd.read_csv(file,header = 0,index_col = 0)\n",
    "\n",
    "    #Get the values\n",
    "    X = dataset.values[:,1:(dataset.shape[1]-1)]\n",
    "    Y = dataset.values[:,0]\n",
    "    \n",
    "    #Set splitting parameters\n",
    "    validation_size = 0.20\n",
    "    seed = seed\n",
    "    \n",
    "    #Split data\n",
    "    X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed) \n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetTrainingData(UserInput):\n",
    "    \"\"\"\n",
    "    Returns X_train, Y_train\n",
    "    \n",
    "    getGraphs(UserInput)\n",
    "        UserInput - Dictionary of relevant info (see UserInputs2WorkingForm)\n",
    "        )\n",
    "    \n",
    "    This returns the training and test sets\n",
    "    \"\"\"\n",
    "    \n",
    "    #Find training file name and read it\n",
    "    for file in UserInput['Working Directory']:\n",
    "        if file == UserInput['TrainingFileName']:\n",
    "            dataset = pd.read_csv(file,header = 0,index_col = 0)\n",
    "\n",
    "    #Return the entire sets\n",
    "    X_train = dataset.values[:,1:(dataset.shape[1]-1)]\n",
    "    Y_train = dataset.values[:,0]\n",
    "    \n",
    "    return X_train, Y_train, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetTESTDataFrameNames(UserInput):\n",
    "    \"\"\"\n",
    "    Returns an array of strings\n",
    "    \n",
    "    GetTESTDataFrameNames(\n",
    "        UserInput - Dictionary of relevant info (see UserInputs2WorkingForm)\n",
    "        )\n",
    "    \n",
    "    This returns the names of each column of the training file\n",
    "    \"\"\"\n",
    "    \n",
    "    #Find training file name and read it\n",
    "    for file in UserInput['Working Directory']:\n",
    "        if file == UserInput['TrainingFileName']:\n",
    "            dataset = pd.read_csv(file,header = 0,index_col = 0)\n",
    "            \n",
    "    #Instantiate\n",
    "    names = []\n",
    "    \n",
    "    #Get names\n",
    "    for x in dataset.columns:\n",
    "        names.append(x)\n",
    "    \n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModel(X_train,Y_train):\n",
    "    \"\"\"\n",
    "    Returns a classifier that has been fit\n",
    "    \n",
    "    TrainModel(\n",
    "        X_train - Training Data\n",
    "        Y_train - Results of Training Data for supervised learning\n",
    "        )\n",
    "    \n",
    "    Currently only fits RandomForestClassifier\n",
    "    \"\"\"\n",
    "    \n",
    "    #Fit final model\n",
    "    classifier = RandomForestClassifier(min_samples_split= 10 ,n_estimators = 200)\n",
    "    classifier = classifier.fit(X_train, Y_train)\n",
    "    \n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(value,dictionary): \n",
    "    \"\"\"\n",
    "    \n",
    "    Modified from:\n",
    "    https://www.geeksforgeeks.org/python-get-key-from-value-in-dictionary/\n",
    "    \"\"\"\n",
    "    \n",
    "    #Return key if the value in dictionary is the predetermined value\n",
    "    result = []\n",
    "    for x in value:\n",
    "        for key, val in dictionary.items(): \n",
    "             if val == x:\n",
    "                result.append( key )\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PredictModel(classifier,X_test):\n",
    "    \"\"\"\n",
    "    Returns a tuple of prediction in integer form, string form\n",
    "    \n",
    "    PredictModel(\n",
    "        classifier - fitted classifier\n",
    "        X_test - data to be tested\n",
    "        )\n",
    "    \"\"\"\n",
    "    #Get key-value relationship\n",
    "    State2Int = StateDict()\n",
    "    \n",
    "    #Predict\n",
    "    Y_test_pred = classifier.predict(X_test)\n",
    "    \n",
    "    #Get string (key) of the prediction\n",
    "    Y_test_pred_string = get_key(Y_test_pred,State2Int)\n",
    "    \n",
    "    return Y_test_pred, Y_test_pred_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PredictProbModel(classifier,X_test):\n",
    "    \"\"\"\n",
    "    Returns a prediction probability (out of 100 not 1)\n",
    "    \n",
    "    PredictModel(\n",
    "        classifier - fitted classifier\n",
    "        X_test - data to be tested\n",
    "        )\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    COMBINE WITH PREDICT MODEL GOING FORWARD\n",
    "    \"\"\"\n",
    "    \n",
    "    #Get the probability prediction\n",
    "    Y_test_pred_proba = classifier.predict_proba(X_test)\n",
    "    \n",
    "    return Y_test_pred_proba*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetUserInputNames(UserInput):\n",
    "    \"\"\"\n",
    "    Returns an array of strings\n",
    "    \n",
    "    GetUserInputNames(\n",
    "        UserInput - Dictionary of relevant info (see UserInputs2WorkingForm)\n",
    "        )\n",
    "    \n",
    "    This returns the names of the columns in UserInput\n",
    "    \"\"\"\n",
    "    #Instantiate\n",
    "    names = []\n",
    "    \n",
    "    #Append names\n",
    "    for x in UserInput:\n",
    "        names.append(x)\n",
    "    \n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FeatureComparison(models,X_train, X_test, Y_train, Y_test,UserInput):\n",
    "    \"\"\"\n",
    "    returns tuple: \n",
    "        results - an array of classification results\n",
    "        string - an array of classifier names and classification results\n",
    "        string1 - an array of classifiers that do not have feature importance graphs\n",
    "        time - an array of time stamps recording how long a fit/prediction/classification\n",
    "                result took for an figure\n",
    "        fig - an array of figures containing feature importance for classifiers\n",
    "        \n",
    "    FeatureComparison(\n",
    "        models - an array of classifiers for testing\n",
    "        X_train - Training Data\n",
    "        X_test - Data to be fitted\n",
    "        Y_train - Results of Training Data for supervised learning\n",
    "        Y_test - results of the fitted data\n",
    "        UserInput - Dictionary of relevant info (see UserInputs2WorkingForm)\n",
    "        )\n",
    "        \n",
    "    The function usefullness lies in its ability to test mass quantities of classifiers\n",
    "    \"\"\"\n",
    "    \n",
    "    #Instantiate\n",
    "    results = []\n",
    "    string = []\n",
    "    string1 = []\n",
    "    fig = []\n",
    "    time = []\n",
    "    \n",
    "    #Apppend when appropriate\n",
    "    for ModelName in models:\n",
    "        \n",
    "        #Time process time\n",
    "        before = datetime.now()\n",
    "        \n",
    "        #Fit Model\n",
    "        error = False\n",
    "        try:\n",
    "            CTest = models[ModelName].fit(X_train, Y_train)\n",
    "        except:\n",
    "            print()\n",
    "            error = True\n",
    "        \n",
    "        #Classification report\n",
    "        if not error:\n",
    "            try:\n",
    "                Y_pred = CTest.predict(X_test)\n",
    "                temporary = classification_report(Y_test,Y_pred)\n",
    "                results.append(temporary)\n",
    "                #CTest.score(X_test, Y_test))) #optional metric\n",
    "                string.append(\"{} has the following results: \\n\\n {} \\n\\n\".format(ModelName,temporary))\n",
    "            except:\n",
    "                try:\n",
    "                    Y_pred = CTest.predict(X_test)\n",
    "                    temporary = classification_report(Y_test,np.round_(Y_pred)) #try rounding Y_pred\n",
    "                    results.append(temporary)\n",
    "                    #CTest.score(X_test, Y_test))) #optional metric\n",
    "                    string.append(\"{} has the following results: \\n\\n {} \\n\\n\".format(ModelName,temporary))\n",
    "                except:    \n",
    "                    string.append(\"{} failed during classification_report.\".format(ModelName))\n",
    "        else:\n",
    "            string.append(\"{} failed during the fit.\".format(ModelName))\n",
    "        \n",
    "        #Time fitting and scoring\n",
    "        end = datetime.now()\n",
    "        time.append(\"{} took {} time\".format(ModelName,(end-before)))\n",
    "        \n",
    "        #Try figures\n",
    "        try:\n",
    "            m = CTest.feature_importances_\n",
    "            m1 = GetTESTDataFrameNames(UserInput)\n",
    "            Z = [x for _,x in sorted(zip(m,m1))]\n",
    "            Z1 = sorted(m)\n",
    "            fig.append(getBarPlot(Z1[-10:],Z[-10:],\"Relative Importance\",ModelName))\n",
    "        except:\n",
    "            string1.append(\"{} has no feature importance\".format(ModelName)) \n",
    "            \n",
    "    return results,string,string1,time,fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateComparisonResultFiles(results,string,string1,time,fig,str1 = \"Graphs.pdf\",\\\n",
    "                                  str2 = \"Time.txt\",str3 = \"NoGraphs.txt\",str4 = \"Scoring.txt\"):\n",
    "    \"\"\"\n",
    "    returns true value upon completion\n",
    "    \n",
    "    GenerateComparisonResultFiles(\n",
    "        results - an array of classification results\n",
    "        string - an array of classifier names and classification results\n",
    "        string1 - an array of classifiers that do not have feature importance graphs\n",
    "        time - an array of time stamps recording how long a fit/prediction/classification\n",
    "                result took for an figure\n",
    "        fig - an array of figures containing feature importance for classifiers\n",
    "        str1 - title of pdf file relating to figs (Default: \"Graphs.pdf\")\n",
    "        str2 = title of txt file relating to time (Default: Time.txt\")\n",
    "        str3 = title of txt file relating to string1 (Default: \"NoGraphs.txt\")\n",
    "        str4 = title of txt file relating to string (Default: \"Scoring.txt\")\n",
    "        )\n",
    "        \n",
    "    The function generates 4 files.\n",
    "    This function is to be used after FeatureComparison()\n",
    "    \"\"\"\n",
    "    #PDF of figures\n",
    "    pdf = matplotlib.backends.backend_pdf.PdfPages(str1)\n",
    "    i = 0\n",
    "    for figure in fig:\n",
    "        pdf.savefig( fig[i],dpi=300, bbox_inches = \"tight\")\n",
    "        i += 1\n",
    "    pdf.close()\n",
    "\n",
    "    #.txt of Time\n",
    "    if not(not time):\n",
    "        with open(str2, 'w') as writeFile:\n",
    "            for i in np.arange(len(time)):\n",
    "                writeFile.write(\"%(t)s\\n\" % {\"t\":time[i]})\n",
    "    writeFile.close()   \n",
    "\n",
    "    #.txt of NoGraphs\n",
    "    if not(not string1):\n",
    "        with open(str3, 'w') as writeFile:\n",
    "            for i in np.arange(len(string1)):\n",
    "                writeFile.write(\"%(t)s\\n\" % {\"t\":string1[i]})\n",
    "    writeFile.close()       \n",
    "\n",
    "    #.txt Scoring Results\n",
    "    if not(not string):\n",
    "        with open(str4, 'w') as writeFile:\n",
    "            for i in np.arange(len(string)):\n",
    "                writeFile.write(\"%(t)s\\n\" % {\"t\":string[i]})\n",
    "    writeFile.close()\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SignalGenerator(t):\n",
    "    \"\"\"\n",
    "    returns numpy.ndarray\n",
    "    \n",
    "    SignalGenerator(\n",
    "        t - numpy.ndarray\n",
    "        )\n",
    "        \n",
    "    The file generates a random sine wave combination with white noise\n",
    "    given an input time series\n",
    "    \"\"\"\n",
    "    #Signal generator for practice\n",
    "    noise1 = np.random.randn(len(t))                # white noise 1\n",
    "    noise2 = np.random.randn(len(t))                # white noise 2 \n",
    "    noise3 = np.random.randn(len(t))                # white noise 3\n",
    "    phase  = np.random.randn(3)                     #radians\n",
    "    frequency1 = np.random.randint(1,1000)          #Hz\n",
    "    frequency2 = np.random.randint(1,1000)          #Hz\n",
    "    frequency3 = np.random.randint(1,1000)          #Hz\n",
    "    mag = np.random.randn(3)\n",
    "    base1 = mag[0] * np.sin(2 * np.pi * frequency1 * t + phase[0] ) + noise1  #base signal\n",
    "    base2 = mag[1] * np.sin(2 * np.pi * frequency2 * t + phase[1] ) + noise2  #base signal\n",
    "    base3 = mag[2] * np.sin(2 * np.pi * frequency3 * t + phase[2] ) + noise3  #base signal\n",
    "    return base1 + base2 + base3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateTrainingFile(string):\n",
    "    \"\"\"\n",
    "    returns True upon completition\n",
    "    \n",
    "    GenerateTrainingFile(\n",
    "        string - filename of CSV files (include CSV extension)\n",
    "    )\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #Hard Coded file and changing directories\n",
    "    #This is where the data is\n",
    "    HomeDirectory = \"/Users/tbryan/Desktop/9 2019 Fall/ECEN 403/Programming/ProgramsForDemo/Final\"\n",
    "    os.chdir(HomeDirectory)\n",
    "    os.chdir('Data')\n",
    "    os.chdir('IMS')\n",
    "    directory = [sorted(os.listdir('1st_test')),sorted(os.listdir('2nd_test')),sorted(os.listdir('3rd_test/txt'))]\n",
    "\n",
    "    #directory.remove(\".DS_Store\")\n",
    "    os.chdir('1st_test')\n",
    "    #IMSDictionary = GenerateIMSDictionary('2003.10.22.12.06.24',\"DELETE.csv\",os.getcwd())\n",
    "    IMSDictionary = GenerateIMSDictionary('2003.10.22.12.06.24',\" \",os.getcwd())\n",
    "\n",
    "    #Instantiate\n",
    "    m1 = []\n",
    "    m2 = []\n",
    "    m3 = []\n",
    "    m4 = []\n",
    "    m1y = []\n",
    "    m2y = []\n",
    "    m3y = []\n",
    "    m4y = []\n",
    "    \n",
    "    #For each test \n",
    "    for j in range(0,1):\n",
    "        \n",
    "        #For each file\n",
    "        i = 0\n",
    "        while i < len(directory[j]):\n",
    "        #while i < 20:\n",
    "            if directory[j][i] != \".DS_Store\":\n",
    "                \n",
    "                #Read Data\n",
    "                data = pd.read_table(directory[j][i],header = None)\n",
    "                \n",
    "                #Get each bearing from file\n",
    "                DF = ReplaceSignalDataofInterest(np.transpose(data.values[:,0]),IMSDictionary,directory[j][i])\n",
    "                B1X = getCompleteDataFrame(DF,1)\n",
    "                DF = ReplaceSignalDataofInterest(np.transpose(data.values[:,1]),IMSDictionary,directory[j][i])\n",
    "                B1Y = getCompleteDataFrame(DF,1)\n",
    "                DF = ReplaceSignalDataofInterest(np.transpose(data.values[:,2]),IMSDictionary,directory[j][i])\n",
    "                B2X = getCompleteDataFrame(DF,2)\n",
    "                DF = ReplaceSignalDataofInterest(np.transpose(data.values[:,3]),IMSDictionary,directory[j][i])\n",
    "                B2Y = getCompleteDataFrame(DF,2)\n",
    "                DF = ReplaceSignalDataofInterest(np.transpose(data.values[:,4]),IMSDictionary,directory[j][i])\n",
    "                B3X = getCompleteDataFrame(DF,3)\n",
    "                DF = ReplaceSignalDataofInterest(np.transpose(data.values[:,5]),IMSDictionary,directory[j][i])\n",
    "                B3Y = getCompleteDataFrame(DF,3)\n",
    "                DF = ReplaceSignalDataofInterest(np.transpose(data.values[:,6]),IMSDictionary,directory[j][i])\n",
    "                B4X = getCompleteDataFrame(DF,4)\n",
    "                DF = ReplaceSignalDataofInterest(np.transpose(data.values[:,7]),IMSDictionary,directory[j][i])\n",
    "                B4Y = getCompleteDataFrame(DF,4)\n",
    "                \n",
    "                #Get Column Title\n",
    "                ColumnTitle = B1X.columns\n",
    "                \n",
    "                #Append arrays\n",
    "                m1.append(B1X.values[0,:])\n",
    "                m1y.append(B1Y.values[0,:])\n",
    "                m2.append(B2X.values[0,:])\n",
    "                m2y.append(B2Y.values[0,:])\n",
    "                m3.append(B3X.values[0,:])\n",
    "                m3y.append(B3Y.values[0,:])\n",
    "                m4.append(B4X.values[0,:])\n",
    "                m4y.append(B4Y.values[0,:])\n",
    "                i += 1\n",
    "            else:\n",
    "                i += 1\n",
    "\n",
    "        #To dataframes\n",
    "        B1X = pd.DataFrame(m1,columns = ColumnTitle)\n",
    "        B1Y = pd.DataFrame(m1y,columns = ColumnTitle)\n",
    "        B2X = pd.DataFrame(m2,columns = ColumnTitle)\n",
    "        B2Y = pd.DataFrame(m2y,columns = ColumnTitle)\n",
    "        B3X = pd.DataFrame(m3,columns = ColumnTitle)\n",
    "        B3Y = pd.DataFrame(m3y,columns = ColumnTitle)\n",
    "        B4X = pd.DataFrame(m4,columns = ColumnTitle)\n",
    "        B4Y = pd.DataFrame(m4y,columns = ColumnTitle)\n",
    "        \n",
    "        #Combine Dataframes\n",
    "        TD = B1X\n",
    "        TD = TD.append(B1Y)\n",
    "        TD = TD.append(B2X)\n",
    "        TD = TD.append(B2Y)\n",
    "        TD = TD.append(B3X)\n",
    "        TD = TD.append(B3Y)\n",
    "        TD = TD.append(B4X)\n",
    "        TD = TD.append(B4Y)\n",
    "\n",
    "    os.chdir(HomeDirectory)\n",
    "    \n",
    "    #To csv\n",
    "    TD.to_csv(string)\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetFinalModelForComparison(MinSampleSplit=2, Nestimators = 10):\n",
    "    \"\"\"\n",
    "    Returns a dictionary of the the final ML classifier with ability to change the \n",
    "    min_samples_split and n_estimators setting\n",
    "    \n",
    "    GetFinalModelForComparison(MinSampleSplit=2, Nestimators = 10)\n",
    "    \"\"\"\n",
    "    #Arrange\n",
    "    models = {\n",
    "        'RandomForestClassifier': RandomForestClassifier(min_samples_split=MinSampleSplit,n_estimators = Nestimators),\n",
    "        \n",
    "        }\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StateDict():\n",
    "    \"\"\"\n",
    "    Returns a dictionary \"Key\": Value\n",
    "    \n",
    "    StateDict()\n",
    "    \n",
    "    The key is the more verbose describtion of the output state of the training data\n",
    "    The value is the int that is defined to relate to the corresponding key. \n",
    "    \"\"\"\n",
    "    \n",
    "    State2Int = {\n",
    "        \"Early\": 0,\n",
    "        \"Suspect\": 1,\n",
    "        \"Normal\": 2,\n",
    "        \"Imminent Failure\": 3,\n",
    "        \"Inner Race Failure\": 4, \n",
    "        \"Rolling Element Failure\": 5,\n",
    "        \"Stage 2 Failure\": 6,\n",
    "        \"ERROR\": 77777\n",
    "    }\n",
    "    \n",
    "    return State2Int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetReducedFeatureArraysFromDataFrame(dataset):\n",
    "    \"\"\"\n",
    "    Returns tuple: ReducedFeatureTrainingData, dataset[['State']]\n",
    "    ReducedFeatureTrainingData - dictionary of feature extraction dataframes\n",
    "    dataset[['State']] - corresponding dataframe with outcome states\n",
    "    \n",
    "    GetReducedFeatureArraysFromDataFrame(\n",
    "        dataset - dataframe containing the training data\n",
    "        )\n",
    "    \"\"\"\n",
    "    \n",
    "    #Feature Extraction\n",
    "    ReducedFeatureTrainingData = {\n",
    "        '2':  dataset[['RMS','FTF']],\n",
    "        '3':  dataset[['RMS','FTF','Max ABS']],\n",
    "        '4':  dataset[['RMS','FTF','Max ABS','Skew']],\n",
    "        '5':  dataset[['RMS','FTF','Max ABS','Skew','PSD Frq @ Peak 5']],\n",
    "        '6':  dataset[['RMS','FTF','Max ABS','Skew','PSD Frq @ Peak 5','Autocorrelate Time @ Peak 5']],\n",
    "        '7':  dataset[['RMS','FTF','Max ABS','Skew','PSD Frq @ Peak 5','Autocorrelate Time @ Peak 5','Min']],\n",
    "        '8':  dataset[['RMS','FTF','Max ABS','Skew','PSD Frq @ Peak 5','Autocorrelate Time @ Peak 5','Min','PSD Frq @ Peak 1']],\n",
    "        '9':  dataset[['RMS','FTF','Max ABS','Skew','PSD Frq @ Peak 5','Autocorrelate Time @ Peak 5','Min','PSD Frq @ Peak 1','FFT Frq @ Peak 1']],\n",
    "        '10': dataset[['RMS','FTF','Max ABS','Skew','PSD Frq @ Peak 5','Autocorrelate Time @ Peak 5','Min','PSD Frq @ Peak 1','FFT Frq @ Peak 1','PSD Frq @ Peak 2']],\n",
    "        '3a': dataset[['RMS','Max ABS','Skew']],\n",
    "        '4a': dataset[['RMS','Max ABS','Skew','Max']],\n",
    "        '5a': dataset[['RMS','Max ABS','Skew','Max','Min']],\n",
    "        'all': dataset.drop(columns=['State'])\n",
    "    }\n",
    "    \n",
    "    return ReducedFeatureTrainingData, dataset[['State']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetFinalReducedFeatureArraysFromDataFrame(dataset):\n",
    "    \"\"\"\n",
    "    Returns tuple: ReducedFeatureTrainingData, dataset[['State']]\n",
    "    ReducedFeatureTrainingData - dictionary of feature extraction dataframes\n",
    "    dataset[['State']] - corresponding dataframe with outcome states\n",
    "    \n",
    "    GetFinalReducedFeatureArraysFromDataFrame(\n",
    "        dataset - dataframe containing the training data\n",
    "        )\n",
    "    \"\"\"\n",
    "    \n",
    "    #Feature Extraction\n",
    "    #Similar to GetReducedFeatureArraysFromDataFrame() with on the '10' state\n",
    "    ReducedFeatureTrainingData = {\n",
    "        '10': dataset[['RMS','FTF','Max ABS','Skew','PSD Frq @ Peak 5','Autocorrelate Time @ Peak 5','Min','PSD Frq @ Peak 1','FFT Frq @ Peak 1','PSD Frq @ Peak 2']],\n",
    "    }\n",
    "    \n",
    "    return ReducedFeatureTrainingData, dataset[['State']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get10FeaturesFromDataFrame(df):\n",
    "    \"\"\"\n",
    "    Returns a dataframe of the 10 important features\n",
    "    \n",
    "    Get10FeaturesFromDataFrame(\n",
    "        df - dataframe of the getTestDataFrame that contains the data to be analyzed\n",
    "        )\n",
    "    \"\"\"\n",
    "    #Extract Features\n",
    "    x = df[['RMS','FTF','Max ABS','Skew','PSD Frq @ Peak 5','Autocorrelate Time @ Peak 5','Min','PSD Frq @ Peak 1','FFT Frq @ Peak 1','PSD Frq @ Peak 2']]\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReducedFeatureComparison(ReducedFeatureTrainingData,StateTrain):\n",
    "    \"\"\"\n",
    "    Returns tuple: results, header which are strings\n",
    "    results- contains classification reports\n",
    "    header- contains formatted strings\n",
    "    \n",
    "    ReducedFeatureComparison(\n",
    "        ReducedFeatureTrainingData - dictionary of dataframes with extracted features\n",
    "        StateTrain - dataframe of the outcome states associated with ReducedFeatureTrainingData\n",
    "    )\n",
    "    \"\"\"\n",
    "    \n",
    "    #Instantiate\n",
    "    result = []\n",
    "    header = []\n",
    "    \n",
    "    #Set Splitting Features\n",
    "    validation_size = 0.20\n",
    "    seed = 6\n",
    "    \n",
    "    #For each combination of Feature Extraction Models\n",
    "    for set in ReducedFeatureTrainingData:\n",
    "        \n",
    "        #Get Values \n",
    "        FeatureTrain = ReducedFeatureTrainingData[set].values\n",
    "        \n",
    "        #Split\n",
    "        xtrain, xtest, ytrain, ytest = model_selection.train_test_split(FeatureTrain, StateTrain.values[:,0], test_size=validation_size, random_state=seed) \n",
    "        \n",
    "        #Train\n",
    "        ClassifierReduced = TrainModel(xtrain,ytrain)\n",
    "        \n",
    "        #Predict\n",
    "        ypred,ypredstring = PredictModel(ClassifierReduced,xtest)\n",
    "        \n",
    "        #Append strings\n",
    "        result.append(classification_report(ytest,ypred))\n",
    "        header.append('Feature Number ({}):'.format(set))\n",
    "            \n",
    "    return result,header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateFeatureFile(string,result,header):\n",
    "    \"\"\"\n",
    "    Returns True upon completition\n",
    "    \n",
    "    GenerateFeatureFile(\n",
    "        string - string with file name (include extension')\n",
    "        results- contains classification reports\n",
    "        header - contains formatted strings\n",
    "    )\n",
    "    \"\"\"\n",
    "    \n",
    "    #Write to file\n",
    "    with open(string, 'w') as writeFile:\n",
    "        for i in np.arange(len(result)):\n",
    "            writeFile.write(\"{}\\n{}\\n\".format(header[i],result[i]))\n",
    "    writeFile.close() \n",
    "    \n",
    "    return True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
